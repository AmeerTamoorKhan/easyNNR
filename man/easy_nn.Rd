% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/easy_nn.R
\name{easy_nn}
\alias{easy_nn}
\title{easy_nn: One-Function Neural Network Training}
\usage{
easy_nn(
  data,
  target,
  task = NULL,
  exclude = NULL,
  test_split = 0.2,
  validation_split = 0.2,
  layers = c(128, 64),
  activations = NULL,
  dropout = NULL,
  batch_norm = FALSE,
  optimizer = "adam",
  learning_rate = 0.001,
  loss = NULL,
  metrics = NULL,
  epochs = 50,
  batch_size = 32,
  early_stopping = TRUE,
  patience = 15,
  scale_data = TRUE,
  seed = 42,
  verbose = TRUE,
  preprocess = list()
)
}
\arguments{
\item{data}{A data frame containing your dataset}

\item{target}{Character string specifying the name of the target variable (column to predict)}

\item{task}{Character string: "regression" or "classification" (auto-detected if NULL)}

\item{exclude}{Character vector of column names to exclude from training (e.g., IDs, dates)}

\item{test_split}{Proportion of data to use for testing (default: 0.2)}

\item{validation_split}{Proportion of training data to use for validation (default: 0.2)}

\item{layers}{Integer vector specifying neurons in each hidden layer (default: c(128, 64))}

\item{activations}{Character vector of activation functions for each layer (default: "relu")}

\item{dropout}{Numeric vector of dropout rates for each layer (default: NULL, no dropout)}

\item{batch_norm}{Logical, whether to use batch normalization (default: FALSE)}

\item{optimizer}{Character string: "adam", "rmsprop", "sgd", "adamw", etc. (default: "adam")}

\item{learning_rate}{Numeric, learning rate for optimizer (default: 0.001)}

\item{loss}{Character string, custom loss function (auto-detected if NULL)}

\item{metrics}{Character vector of metrics to track (auto-detected if NULL)}

\item{epochs}{Integer, number of training epochs (default: 50)}

\item{batch_size}{Integer, batch size for training (default: 32)}

\item{early_stopping}{Logical, whether to use early stopping (default: TRUE)}

\item{patience}{Integer, epochs to wait before early stopping (default: 15)}

\item{scale_data}{Logical or character, scaling method: TRUE/"standard", "minmax", "robust", "maxabs", "quantile", or FALSE (default: TRUE)}

\item{seed}{Integer, random seed for reproducibility (default: 42)}

\item{verbose}{Logical, whether to print detailed training progress (default: TRUE)}

\item{preprocess}{List of preprocessing options (see Details)}
}
\value{
An 'easyNNR' object (S3 list) containing:
\itemize{
  \item \strong{model}: Trained Keras model
  \item \strong{history}: Training history as tidy tibble
  \item \strong{evaluation}: Test set performance metrics
  \item \strong{predictions}: Test set predictions with actuals
  \item \strong{recipe}: Preprocessing recipe for reuse
  \item \strong{target}: Target variable name
  \item \strong{exclude}: Excluded columns
  \item \strong{parameters}: Model configuration and hyperparameters
  \item \strong{preprocessing}: Preprocessing configuration and transformers
}
}
\description{
A single-function solution for building, training, and evaluating neural networks in R.
Perfect for beginners and researchers who want quick results without deep learning expertise.
Compatible with TensorFlow 2.15.0 and Keras 2.15.0.
}
\details{
The \code{preprocess} parameter accepts a list with the following options:

\strong{Outlier Handling:}
\itemize{
  \item \code{outlier_method}: "none", "iqr", "zscore", "isolation_forest", "winsorize", "cap", "remove" (default: "none")
  \item \code{outlier_threshold}: Threshold for outlier detection (default: 1.5 for IQR, 3 for zscore)
}

\strong{Target Transformation (Regression):}
\itemize{
  \item \code{target_transform}: "none", "log", "log1p", "sqrt", "boxcox", "yeojohnson", "quantile" (default: "none")
}

\strong{Class Imbalance (Classification):}
\itemize{
  \item \code{imbalance_method}: "none", "oversample", "undersample", "smote", "adasyn", "class_weights" (default: "none")
  \item \code{imbalance_ratio}: Target ratio for resampling (default: 1.0)
}

\strong{Feature Selection:}
\itemize{
  \item \code{feature_selection}: "none", "variance", "correlation", "mutual_info", "rfe", "lasso" (default: "none")
  \item \code{n_features}: Number of features to select (default: NULL, auto)
  \item \code{correlation_threshold}: Threshold for correlation filter (default: 0.9)
}

\strong{Encoding Methods:}
\itemize{
  \item \code{encoding}: "onehot", "target", "frequency", "binary", "hash" (default: "onehot")
  \item \code{max_categories}: Max categories for one-hot encoding (default: 50)
}

\strong{Imputation:}
\itemize{
  \item \code{impute_numeric}: "median", "mean", "knn", "iterative", "constant" (default: "median")
  \item \code{impute_categorical}: "mode", "constant", "missing_category" (default: "mode")
  \item \code{add_indicators}: Logical, add missingness indicator columns (default: FALSE)
}

\strong{Feature Engineering:}
\itemize{
  \item \code{interactions}: Logical or formula, create interaction terms (default: FALSE
  \item \code{polynomial_degree}: Integer, degree for polynomial features (default: 1, no polynomial)
  \item \code{pca_components}: Number of PCA components (default: NULL, no PCA)
}

\strong{Time Series Features:}
\itemize{
  \item \code{date_features}: Logical, extract features from date columns (default: FALSE)
  \item \code{lag_features}: Integer vector of lag periods (default: NULL)
  \item \code{rolling_features}: List with window sizes for rolling statistics (default: NULL)
}
}
\examples{
\dontrun{
# Simple classification
library(easyNNR)
data(iris)
model <- easy_nn(iris, target = "Species")

# Regression with preprocessing
data(mtcars)
model <- easy_nn(
  data = mtcars,
  target = "mpg",
  task = "regression",
  layers = c(256, 128, 64),
  preprocess = list(
    outlier_method = "winsorize",
    target_transform = "log",
    feature_selection = "correlation"
  )
)

# Classification with imbalance handling
model <- easy_nn(
  data = imbalanced_data,
  target = "class",
  preprocess = list(
    imbalance_method = "smote",
    encoding = "target",
    feature_selection = "mutual_info",
    n_features = 20
  )
)
}

}
